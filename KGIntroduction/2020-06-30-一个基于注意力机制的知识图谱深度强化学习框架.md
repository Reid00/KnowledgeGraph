---
layout:     post                    # 使用的布局（不需要改）
title:      一个基于注意力机制的知识图谱深度强化学习框架				      # 标题 
subtitle:   ADRL		 #副标题
date:       2020-06-30        # 时间
author:     Reid                      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
- 知识图谱
- Knowledge Graph, KG
- ADRL
---

## 

source page:  https://mp.weixin.qq.com/s/B-jLijqqKA3XFrANF0uoBQ



**概要与动机**

知识图谱推理是图谱构建的关键技术之一，它在包括垂直搜索和智能问答等应用场景中有着重要作用。推理的目标是根据已知实体和关系推断所需的未知实体。现有的推理方法主要基于embedding实现（即对所有的实体和关系做整体embedding，然后利用向量相似度推断实体间的关系或者给定三元组是否为真）。但是在真实的应用场景中，我们需要一个清晰且可解释的实体作为输出。本文提出一种基于注意力机制的知识图谱深度强化学习框架ADRL，用于学习多跳关系路径，通过深度学习及强化学习结构化感知，从而提高传统方法效率，泛化能力及可解释性。

**贡献**

本文的主要贡献包括：

1.提出了一个面向知识图谱推理的基于深度学习的新框架，相较传统方法，该框架科研有效提升性能及可解释性

2.设计了一个关系模型，作为推理框架的通用插件，其中的self-attention能够循环推断实体之间的关系以引导一个model-free的策略，这一做法相对前人工作更有助于agent推断关系路径

3.利用actor-critic方法有效解决了奖励系数问题，其中奖励取决于价值函数，并将同策略一起被训练和优化

**模型与算法**

本文提出框架的整个过程如下图所示，其过程大体可以描述为：

1.首先将知识图谱的agent环境输入卷积神经网络（CNN）；

2.利用深度CNN将其映射到低维向量，且可以在每个级别可以传递信息

3.接着使用LSTM（使用校正的线路单ReLU激活函数），用于储存生成的历史轨迹，构成策略与价值函数

4.上述步骤的输出被输入进一个关系模型，模型中包含一个self-attention模块用于推断和分享实体向量及关系向量的权值

5.利用一个特征感知的最大池化层对关系模型的输出进行聚合，最后传递给一个MLP接着是ReLU激活函数用于产生一个策略以及一个基准标量价值函数，可以被用作一个agent奖励

![img](https://mmbiz.qpic.cn/mmbiz_png/GNpj5fw72EqqXXiaEOVVod8yPUwM1QBCESrrejQDYGC9seLYz9tkFwheMsib3HvVD84b6ia720oohQVPGDlGicXTyg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在优化算法方面，作者考虑到基于梯度下降的方法效率较低，而蒙特卡洛抽样依赖于大量积极奖励（尤其是学习初始阶段），为了解决这些问题，作者选择Actor-Critic，一种结合策略梯度和顺序差异学习的强化学习方法。Actor-Critic算法可以执行单步更新参数，使用值函数作为基础函数来减少策略梯度的差异，而无需等待回合结束，并且在训练过程中可以同时学习策略和价值函数，算法流程如下图：

![img](https://mmbiz.qpic.cn/mmbiz_png/GNpj5fw72EqqXXiaEOVVod8yPUwM1QBCESrGcbJmqwtlOz7ndgBe5v24Pys7vlhlPYVgkvs4690g4pxlbOGUN1Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**实验与结果**

实验数据：

本文实验所使用的数据是目前较为流行的KG推理数据集（WN18RR,FB15K-237,NELL-995）,其统计信息如表1.

![img](https://mmbiz.qpic.cn/mmbiz_png/GNpj5fw72EqqXXiaEOVVod8yPUwM1QBCEtFsgDqUibo7ic5cDvCiaweogqLxP8QHib03OVVbUqugIhicqyFTcPQYtjLA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

表2是linkprediction实验结果，本文方法展现出了更好的性能，作者认为是共享的实体及关系权值带来了更佳的性能表现。

![img](https://mmbiz.qpic.cn/mmbiz_png/GNpj5fw72EqqXXiaEOVVod8yPUwM1QBCEKZBN6kiaQQdQlXHPd9dVjJQZl4YYwuZgiatmU7X6X5jibhxTNaQ2Bo2nQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

表3是factprediction的结果，作者认为本文方法的优势在于“the reason is that our model is more complex than the previous model, introducing more state-of-the-art methods”

![img](https://mmbiz.qpic.cn/mmbiz_png/GNpj5fw72EqqXXiaEOVVod8yPUwM1QBCE1YOcdsn22NT57icUJosqyhDb7IxZb1x3Xfb4ibGNEsf02na6pePz96sA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)